### importing packages
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pandas.plotting import scatter_matrix
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

### importing data
path=(r"C:\Users\Rohan\Desktop\data science\ineuron\practice group")
data= pd.read_csv(os.path.join(path,'Prestige (1).csv'), 
                  delim_whitespace=True)
data.head()


### Exploring data
data.describe()
data.info()
data.shape
data.index
data['type'].value_counts()

### replacing null values in type with most modal value
data['type']=data['type'].fillna('bc')

### visualizing teh data
plt.hist(data['education'])
data.boxplot(column=['education'])
data.boxplot(column=['women','prestige'])
data.boxplot(column=['census','income'])

attributes = ["education", 'women','prestige', 'census','income']
scatter_matrix(data[attributes], figsize=(12, 8))


### checking for corelations
corrdata=data.corr()
corrdata

### converting categorical data through one hot encoding
from sklearn.preprocessing import OneHotEncoder
cat_encoder=OneHotEncoder(sparse=False, categories='auto')

####################################
type_onehot=cat_encoder.fit_transform(data[['type']])

cat_encoder.categories_

#type_onehot.sparse.to_dense()
type_onehot=pd.DataFrame(type_onehot)
type_onehot.columns=['bc', 'prof', 'wc']
type_onehot.head()
type_onehot.shape

### merging categorical data in one hot form with original numerical dataframe
#datanum= pd.concat([ data,type_onehot], axis=1)
data_type=data['type']
data_type.shape

datanum=pd.merge(data,type_onehot,left_index=True, right_index=True) 

datanum.describe()
datanum.info()
datanum.shape
datanum=datanum.drop(['type'],axis=1)
datanum.head(10)
#######################################################################

#### setting up col transformer and pipeline

from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
num_pipeline = Pipeline([ ('std_scaler', StandardScaler()) ])

from sklearn.compose import ColumnTransformer
num_attribs = list(attributes)
cat_attribs = ["type"]
full_pipeline = ColumnTransformer([
 ("num", num_pipeline, num_attribs),
 ("cat", OneHotEncoder(), cat_attribs),
 ])
data_prepared = full_pipeline.fit_transform(data)

data_prepared1=pd.DataFrame(data_prepared)

data_prepared1.head()
data_prepared1=data_prepared1.rename(columns={0:"education", 1:"income", 2:"women",3:"prestige", 4: "census", 5:'bc', 6:'prof', 7:'wc'})




#### breaking it into train and test
train, test= train_test_split(data_prepared1, test_size=0.2, random_state=800 )
train['bc'].value_counts()

trainlabel=train['income'].copy()
trainfeatures=train.drop(['income'],axis=1)

testlabel=test['income'].copy()
testfeatures=test.drop(['income'],axis=1)
test.head()

#### running initial model of linear regression on train data with rmse                    
linreg=LinearRegression()
linreg.fit(trainfeatures,trainlabel)
linreg.intercept_
linreg.coef_

from sklearn.metrics import mean_squared_error
training_predictions = linreg.predict(trainfeatures)
lin_mse = mean_squared_error(trainlabel, training_predictions)
lin_rmse = np.sqrt(lin_mse)
lin_rmse


#### running initial model of linear regression on train data with rmse 
test_predictions=linreg.predict(testfeatures)
lin_mse_test=mean_squared_error(testlabel, test_predictions)
lin_rmse_test=np.sqrt(lin_mse_test)
lin_rmse_test

#### since plot indicate a polynomial curve, a poly regression is attempted
from sklearn.preprocessing import PolynomialFeatures
poly_features= PolynomialFeatures(degree=2, include_bias=False)
polyreg=poly_features.fit_transform(trainfeatures['prestige'])
polyreg[0]
train.head()


linreg.fit(polyreg,trainlabel)
linreg.intercept_,linreg.coef_

X=data['prestige']
####reshape below is very critical for poly transformation
X_old=X.values.reshape(102,1)
X_old.shape
X_poly=poly_features.transform(X_old)
X_poly[0]
y=data['income']
linreg.fit(X_poly, y)
y_predicted=linreg.predict(X_poly)


plt.plot(X_old,y, 'b .')
plt.plot(X, y_predicted, "r-", linewidth=1, label="Predictions")
plt.show()
